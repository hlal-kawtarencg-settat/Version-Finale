# Version-Finale

# DIABETES ANALYSIS

# A.LARHLIMI

## HLAL KAWTAR

<img src="image7.png" style="height:540px;margin-right:393px"/>

## √âcole Nationale de Commerce et de Gestion (ENCG) - 4√®me Ann√©e


### 1. Le Probl√®me (Business Case)
Dans le domaine m√©dical, le suivi de l‚Äô√©volution d‚Äôune maladie chronique est souvent complexe, car il d√©pend de nombreux facteurs cliniques et biologiques difficilement interpr√©tables conjointement par un m√©decin seul. La variabilit√© inter‚Äëpatient et la charge de travail √©lev√©e peuvent conduire √† une sous‚Äëestimation ou une surestimation de la gravit√© r√©elle de la maladie.

- Objectif : 
Concevoir un mod√®le de pr√©diction de la progression de la maladie (variable cible continue du dataset) √† partir des caract√©ristiques cliniques et biologiques du patient, afin d‚Äôaider le m√©decin √† anticiper l‚Äô√©volution et adapter le traitement.

- Enjeu critique : 
M√™me si la cible est continue, une erreur de pr√©diction n‚Äôa pas le m√™me impact clinique selon qu‚Äôelle sous‚Äëestime ou surestime la gravit√© de la maladie.‚Äã

 Une surestimation de la progression (pr√©dire une maladie plus grave qu‚Äôelle ne l‚Äôest vraiment) peut entra√Æner des traitements plus lourds, des effets secondaires inutiles et des co√ªts suppl√©mentaires pour le syst√®me de sant√©.
 Une sous‚Äëestimation de la progression (pr√©dire une maladie moins avanc√©e qu‚Äôen r√©alit√©) peut retarder la mise en place d‚Äôun traitement adapt√©, aggravant le pronostic du patient et augmentant le risque de complications s√©v√®res.

### Les Donn√©es (L'Input)
Dans ce projet, les donn√©es proviennent d‚Äôun dataset m√©dical r√©el d√©crivant la progression d‚Äôune maladie chronique √† partir de mesures cliniques et biologiques de patients. Le jeu de donn√©es contient 442 observations et 10 variables explicatives normalis√©es, plus une variable cible continue repr√©sentant une mesure de progression de la maladie.

- X (Features) : 10 colonnes correspondant √† des caract√©ristiques num√©riques standardis√©es du patient, telles que l‚Äô√¢ge, le sexe cod√©, l‚Äôindice de masse corporelle (bmi), la pression sanguine (bp) et plusieurs mesures biologiques (s1 √† s6). Ces variables sont d√©j√† centr√©es‚Äër√©duites, ce qui facilite l‚Äôentra√Ænement de mod√®les de r√©gression.

- y (Target) : une variable continue repr√©sentant un score de progression de la maladie, utilis√© comme indicateur de gravit√© ou d‚Äôavancement. Plus la valeur est √©lev√©e, plus la progression de la maladie est importante.

### 2. Le Code Python 

```python
# ==============================================================================
#  DIABETES ANALYSIS
# ==============================================================================

# ------------------------------------------------------------------------------
# 1. IMPORTATION DES BIBLIOTH√àQUES
# ------------------------------------------------------------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Modules Scikit-Learn sp√©cifiques
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor 

# Changed from RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score 

# Changed from accuracy_score, classification_report, confusion_matrix

# Configuration pour des graphiques plus esth√©tiques
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore') 

# Pour garder la sortie propre

print("1. Biblioth√®ques import√©es avec succ√®s.\n")

# ------------------------------------------------------------------------------
# 2. CHARGEMENT DES DONN√âES
# ------------------------------------------------------------------------------

# Chargement du dataset depuis Scikit-Learn
data = load_diabetes()

# Cr√©ation du DataFrame Pandas
# data.data contient les features, data.target contient une mesure quantitative de la progression de la maladie
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

print(f"2. Donn√©es charg√©es. Taille du dataset : {df.shape}")
print(f"   Le target est une variable continue (mesure de progression de la maladie).\n")

# ------------------------------------------------------------------------------
# 3. SIMULATION DE "DONN√âES SALES" (Pour l'exercice)
# ------------------------------------------------------------------------------

# Dans la vraie vie, les donn√©es sont rarement parfaites.
# Nous allons introduire artificiellement des valeurs manquantes (NaN) dans 5% des donn√©es.
print("3. Introduction artificielle de valeurs manquantes (NaN)...")

np.random.seed(42) # Pour la reproductibilit√©
mask = np.random.random(df.shape) < 0.05 # Masque de 5%

# On applique les NaN partout sauf sur la colonne 'target' (qu'on ne veut pas ab√Æmer ici)
features_columns = df.columns[:-1]
df_dirty = df.copy()
for col in features_columns:
    df_dirty.loc[df_dirty.sample(frac=0.05).index, col] = np.nan

print(f"   Nombre total de valeurs manquantes g√©n√©r√©es : {df_dirty.isnull().sum().sum()}\n")

# ------------------------------------------------------------------------------
# 4. NETTOYAGE ET PR√âPARATION (Data Wrangling)
# ------------------------------------------------------------------------------

print("4. Nettoyage des donn√©es...")

# S√©paration Features (X) et Target (y) AVANT le nettoyage pour √©viter les fuites de donn√©es
X = df_dirty.drop('target', axis=1)
y = df_dirty['target']

# Imputation : Remplacer les NaN par la MOYENNE de la colonne
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# On remet sous forme de DataFrame pour garder les noms de colonnes (plus propre)
X_clean = pd.DataFrame(X_imputed, columns=X.columns)

print("   Imputation termin√©e (les NaN ont √©t√© remplac√©s par la moyenne).")
print(f"   Valeurs manquantes restantes : {X_clean.isnull().sum().sum()}\n")

# ------------------------------------------------------------------------------
# 5. ANALYSE EXPLORATOIRE DES DONN√âES (EDA)

# ------------------------------------------------------------------------------
print("5. Analyse Exploratoire (EDA)...")

# A. Aper√ßu statistique
print("   Statistiques descriptives (premi√®res 5 colonnes) :")
print(X_clean.iloc[:, :5].describe())

# B. Visualisation 1 : Distribution d'une feature cl√©
plt.figure(figsize=(10, 5))
feature_to_plot = 'bmi' # Changed from 'mean radius' to 'bmi'
sns.histplot(data=df, x=feature_to_plot, hue='target', kde=True, element="step")
plt.title(f"Distribution de '{feature_to_plot}' selon le diagnostic") # Removed classification labels
plt.show()

# C. Visualisation 2 : Heatmap de corr√©lation (sur les 10 premi√®res variables pour la lisibilit√©)
plt.figure(figsize=(10, 8))
correlation_matrix = X_clean.iloc[:, :10].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Matrice de Corr√©lation (Top 10 Features)")
plt.show()

# ------------------------------------------------------------------------------
# 6. S√âPARATION DES DONN√âES (Train / Test Split)
# ------------------------------------------------------------------------------

# On garde 20% des donn√©es pour le test final
X_train, X_test, y_train, y_test = train_test_split(X_clean, y, test_size=0.2, random_state=42)

print(f"\n6. S√©paration effectu√©e :")
print(f"   Entra√Ænement : {X_train.shape[0]} √©chantillons")
print(f"   Test : {X_test.shape[0]} √©chantillons\n")

# ------------------------------------------------------------------------------
# 7. MOD√âLISATION (Machine Learning)
# ------------------------------------------------------------------------------

print("7. Entra√Ænement du mod√®le (Random Forest Regressor)...") # Updated model name

# Initialisation du mod√®le
model = RandomForestRegressor(n_estimators=100, random_state=42) # Changed to Regressor

# Entra√Ænement sur les donn√©es d'entra√Ænement uniquement
model.fit(X_train, y_train)
print("   Mod√®le entra√Æn√© avec succ√®s.\n")

# ------------------------------------------------------------------------------
# 8. √âVALUATION ET PERFORMANCE
# ------------------------------------------------------------------------------

print("8. √âvaluation des performances...")

# Pr√©dictions sur le jeu de test (donn√©es jamais vues par le mod√®le)
y_pred = model.predict(X_test)

# A. Mean Squared Error (Erreur quadratique moyenne)
mse = mean_squared_error(y_test, y_pred)
print(f"   >>> Mean Squared Error : {mse:.2f}")

# B. R2 Score (Coefficient de d√©termination)
r2 = r2_score(y_test, y_pred)
print(f"   >>> R2 Score : {r2:.2f}")

# C. Visualisation des pr√©dictions vs. r√©alit√© (pour la r√©gression)
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel('Valeurs r√©elles')
plt.ylabel('Pr√©dictions')
plt.title('Pr√©dictions du mod√®le vs. Valeurs r√©elles')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--') # Ligne id√©ale
plt.show()

print("\n--- FIN DU SCRIPT ---")
```
## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

Dans notre projet, des valeurs manquantes (NaN) ont √©t√© introduites artificiellement dans les variables explicatives pour simuler un cas r√©el de donn√©es incompl√®tes, puis totalement imput√©es.  Au total, 220 valeurs manquantes ont √©t√© g√©n√©r√©es puis remplac√©es, et le dataset final ne contient plus aucun NaN avant la phase de mod√©lisation.

### Le probl√®me math√©matique du ¬´ vide ¬ª

La plupart des algorithmes de mod√©lisation utilis√©s en machine learning reposent sur des op√©rations d‚Äôalg√®bre lin√©aire (produits matriciels, inverses, calculs de distances, etc.). Une seule valeur NaN dans une matrice peut rendre ces op√©rations impossibles √† √©valuer num√©riquement, ce qui fait √©chouer le calcul ou donne des r√©sultats non d√©finis. Les biblioth√®ques standards de calcul scientifique (NumPy, scikit‚Äëlearn, etc.) exigent donc en pratique qu‚Äôaucune valeur NaN ne subsiste dans les donn√©es d‚Äôentr√©e des mod√®les.  

### La m√©canique de l‚Äôimputation

Pour traiter ce probl√®me, une √©tape d‚Äôimputation syst√©matique des valeurs manquantes a √©t√© mise en place sur toutes les colonnes num√©riques √† l‚Äôaide d‚Äôun `SimpleImputer(strategy='mean')`.
- **Apprentissage (fit)** : pour chaque feature, l‚Äôimputeur parcourt la colonne et calcule la moyenne Œº uniquement sur les valeurs observ√©es.  
- **Transformation (transform)** : lors du passage suivant, chaque NaN d√©tect√© dans cette colonne est remplac√© par la moyenne Œº pr√©alablement stock√©e, ce qui permet de reconstruire une matrice compl√®te, compatible avec les algorithmes de r√©gression.

Cette approche par la moyenne est simple, stable num√©riquement et conserve la taille du dataset, au prix d‚Äôun lissage de la variabilit√© r√©elle des donn√©es.  

### Le coin de l‚Äôexpert : Data Leakage

Dans ce notebook p√©dagogique, l‚Äôimputation a √©t√© effectu√©e sur l‚Äôensemble du dataset avant la s√©paration en ensembles d‚Äôentra√Ænement et de test.  Cette pratique est tol√©rable en contexte acad√©mique, mais introduit en production un risque de **Data Leakage** (fuite d‚Äôinformation), car les statistiques de nettoyage (ici, les moyennes) utilisent indirectement des informations du futur jeu de test.

La **bonne pratique industrielle** consiste √† :  
1. S√©parer d‚Äôabord les donn√©es en `Train` et `Test`.  
2. Ajuster l‚Äôimputeur (fit) uniquement sur le `Train` pour calculer les moyennes des colonnes.  
3. Appliquer ensuite la transformation (transform) avec ces m√™mes moyennes sur le `Train` et sur le `Test`.  

Ainsi, le mod√®le ne voit jamais, m√™me indirectement, l‚Äôinformation contenue dans le set de test au moment du nettoyage et de l‚Äôapprentissage, ce qui garantit une √©valuation plus honn√™te de ses performances.

## 4. Analyse Approfondie : Exploration (EDA)

L'exploration des donn√©es (EDA) constitue l'√©tape de "profilage" du dataset, permettant de comprendre la structure statistique des variables avant mod√©lisation.  Les statistiques descriptives ont √©t√© calcul√©es sur les 10 features normalis√©es, r√©v√©lant des distributions centr√©es autour de 0 avec des √©carts-types homog√®nes autour de 0.046.

### D√©crypter .describe()

Les statistiques de base fournissent des insights cruciaux sur chaque feature :[1]
- **Mean (Moyenne) vs 50% (M√©diane)** : Les moyennes sont proches de 0 (ex. age : 0.000505, bmi : 0.000197), tout comme les m√©dianes (ex. age : 0.001751, bmi : -0.005128). Cette sym√©trie sugg√®re des distributions **non asym√©triques** (non skewed), sans valeurs extr√™mes tirant fortement la moyenne.  
- **Std (√âcart-type)** : Tous les std sont similaires (~0.046), indiquant une **largeur de distribution coh√©rente** entre features. Aucun std proche de 0, donc toutes les variables portent de l'information (pas de constantes inutiles).
- **Extr√™mes** : Les min/max montrent une variabilit√© raisonnable (ex. s1 : min -0.127 √† max 0.154), confirmant l'efficacit√© de la normalisation centr√©e-r√©duite.

### La multicollin√©arit√© (Le probl√®me de la redondance)

Bien que non explicitement visualis√©e dans le notebook, une analyse de corr√©lation serait pertinente pour d√©tecter la multicollin√©arit√© entre les 10 features biologiques et cliniques.  G√©om√©triquement, des mesures li√©es comme bmi et bp pourraient pr√©senter des corr√©lations √©lev√©es (>0.8), rendant les features redondantes.

**Impact ML** :  
- Pour des mod√®les ensemblistes comme Random Forest, la multicollin√©arit√© est tol√©r√©e (arbre de d√©cision g√®re la redondance).  
- Pour la r√©gression lin√©aire (adapt√©e √† notre cible continue), elle d√©stabilise les coefficients : le mod√®le peine √† attribuer le "poids" pr√©dictif √† une feature unique parmi des variables corr√©l√©es, augmentant la variance des pr√©dictions.

En pratique, une matrice de corr√©lation (heatmap) ou VIF (Variance Inflation Factor) permettrait d'identifier et √©liminer les features les plus redondantes avant mod√©lisation.

## 5. M√©thodologie du split (Train/Test)

Dans ce projet, la s√©paration des donn√©es en ensembles d‚Äôentra√Ænement et de test sert √† √©valuer la capacit√© du mod√®le √† **g√©n√©raliser** sur de nouveaux patients jamais vus pendant l‚Äôapprentissage. Le but n‚Äôest pas de m√©moriser les exemples pass√©s, mais de construire une relation robuste entre les variables cliniques et la progression de la maladie, capable de se transf√©rer au futur.

### Le concept : garantie de g√©n√©ralisation

Si l‚Äôon entra√Ænait et √©valuait le mod√®le sur les m√™mes donn√©es, on mesurerait seulement sa capacit√© √† ¬´ r√©citer ¬ª les cas du pass√©, pas √† pr√©dire correctement de nouveaux cas.  
En r√©servant un sous‚Äëensemble ind√©pendant pour le test, on obtient une estimation plus honn√™te des performances r√©elles en situation clinique, ce qui est essentiel avant d‚Äôenvisager un d√©ploiement aupr√®s de m√©decins.

### Les param√®tres du split

Une s√©paration typique pour ce type de dataset est :  
```python
train_test_split(test_size=0.2, random_state=42)
```
- **Ratio 80/20 (Principe de Pareto)** : environ 80‚ÄØ% des patients sont utilis√©s pour apprendre les motifs complexes entre les features et la progression de la maladie (Train), et 20‚ÄØ% sont conserv√©s pour mesurer la performance sur des donn√©es ¬´ nouvelles ¬ª (Test). Ce compromis laisse suffisamment d‚Äôexemples pour l‚Äôapprentissage tout en gardant un test assez grand pour que la m√©trique soit statistiquement exploitable.  
- **Reproductibilit√© (`random_state=42`)** : le tirage des patients dans Train et Test repose sur un g√©n√©rateur pseudo‚Äëal√©atoire. Fixer la graine (42) garantit que chaque ex√©cution produira exactement la m√™me r√©partition des patients. Cela permet √† un autre chercheur, sur une autre machine, de reproduire √† l‚Äôidentique les r√©sultats du mod√®le, condition indispensable √† une validation scientifique rigoureuse.

## 6. Focus th√©orique : Random Forest üå≤

Le Random Forest est souvent consid√©r√© comme un ¬´ couteau suisse ¬ª du Machine Learning car il est robuste, performant d√®s le premier essai, g√®re bien les non‚Äëlin√©arit√©s et les interactions entre variables, et n√©cessite peu de pr√©paration des donn√©es (peu sensible au scaling, aux distributions bizarres, et assez tol√©rant √† la multicollin√©arit√©). Il s‚Äôadapte aussi bien √† la classification qu‚Äô√† la r√©gression, ce qui en fait un choix par d√©faut tr√®s utilis√© en pratique.

### A. La faiblesse de l‚Äôindividu (Arbre de d√©cision)

Un arbre de d√©cision unique apprend en posant des questions successives du type ¬´ si telle feature > seuil alors aller √† gauche, sinon √† droite ¬ª, jusqu‚Äô√† aboutir √† des feuilles qui donnent une pr√©diction.  
Probl√®me : il a une **variance tr√®s √©lev√©e**. Il peut facilement sur‚Äëapprendre le bruit, par exemple cr√©er une r√®gle tr√®s sp√©cifique pour un patient tr√®s atypique, au lieu de capturer le vrai motif g√©n√©ral. Un changement l√©ger dans les donn√©es d‚Äôentra√Ænement peut compl√®tement changer la forme de l‚Äôarbre.

### B. La force du groupe (Bagging)

Le Random Forest construit non pas un, mais des dizaines voire des centaines d‚Äôarbres, chacun entra√Æn√© dans des conditions l√©g√®rement diff√©rentes.  
Deux sources de ¬´ chaos contr√¥l√© ¬ª sont utilis√©es :  
- **Bootstrapping (√©chantillons diff√©rents)** : chaque arbre est entra√Æn√© sur un √©chantillon tir√© avec remise du dataset (certains patients sont r√©p√©t√©s, d‚Äôautres absents), ce qui donne √† chaque arbre une ¬´ exp√©rience ¬ª diff√©rente.  
- **Feature randomness (colonnes diff√©rentes)** : √† chaque split, l‚Äôarbre ne voit qu‚Äôun sous‚Äëensemble al√©atoire des features, ce qui l‚Äôoblige √† utiliser aussi des variables moins √©videntes au lieu de se reposer toujours sur les plus fortes.  

Cette double randomisation r√©duit fortement la corr√©lation entre arbres et donc la variance globale du mod√®le.

### C. Le consensus (Vote ou moyenne)

Lorsqu‚Äôun nouveau patient arrive :  
- En **classification**, chaque arbre donne une classe (par exemple malade / sain) et la for√™t prend la d√©cision finale par **vote majoritaire**.  
- En **r√©gression**, chaque arbre donne une valeur num√©rique et la for√™t renvoie la **moyenne** des pr√©dictions.  

Parfait, tu suis exactement la structure du corrig√©, mais dans ton cas on est en **r√©gression** (cible continue), pas en classification.

On va donc adapter la partie **‚Äú√âvaluation‚Äù** √† un mod√®le de **r√©gression** (par ex. RandomForestRegressor).

***

## 7. Analyse Approfondie : √âvaluation

Comment lire les r√©sultats comme un pro, quand la cible est continue (progression de maladie) ?

### A. Pas de matrice de confusion en r√©gression

La matrice de confusion suppose des **classes** (malade / sain).  
Ici, on pr√©dit un **score num√©rique** de progression, donc on ne compte pas TP, FP, FN, TN.  
On mesure plut√¥t **l‚Äô√©cart** entre la vraie progression et la progression pr√©dite.

### B. Les m√©triques avanc√©es en r√©gression

Les principales m√©triques pour juger la qualit√© du mod√®le sont :

- **MSE (Mean Squared Error)** : moyenne des carr√©s des erreurs \((y_{\text{r√©el}} - y_{\text{pr√©dit}})^2\).  
  Plus le MSE est bas, plus le mod√®le colle globalement aux valeurs r√©elles.  
- **RMSE (Root Mean Squared Error)** : racine carr√©e du MSE, dans la m√™me unit√© que la cible.  
  Interpr√©tation plus intuitive : ‚Äúerreur moyenne typique‚Äù sur le score de progression.  
- **MAE (Mean Absolute Error)** : moyenne des erreurs absolues \(|y_{\text{r√©el}} - y_{\text{pr√©dit}}|\).  
  Plus robuste aux valeurs extr√™mes : donne l‚Äôerreur moyenne en ‚Äúpoints de progression‚Äù.
- **\(R^2\) (Coefficient de d√©termination)** : varie en g√©n√©ral entre 0 et 1.  
  - 0 : le mod√®le ne fait pas mieux qu‚Äôune pr√©diction constante (la moyenne).  
  - 1 : pr√©diction parfaite.  
  C‚Äôest une mesure de la **proportion de variance expliqu√©e** par le mod√®le.

Dans un contexte m√©dical, la question cl√© est :  
> ¬´ Dans quelle mesure le mod√®le se trompe sur la progression, et ces erreurs sont‚Äëelles cliniquement acceptables ? ¬ª

Par exemple :  
- Un **RMSE faible** signifie que, en moyenne, le mod√®le se trompe peu sur le score de progression.  
- Un **\(R^2\) √©lev√©** signifie que le mod√®le capte bien la relation entre les variables cliniques/biologiques et l‚Äô√©volution de la maladie.

## Conclusion du projet

Ce rapport montre que la Data Science ne s‚Äôarr√™te pas √† `model.fit()`.  
C‚Äôest une cha√Æne de d√©cisions logiques o√π la **compr√©hension du m√©tier m√©dical** dicte :  
- le choix du **type de mod√®le** (ici un Random Forest de r√©gression pour la robustesse face au bruit et aux non‚Äëlin√©arit√©s),  
- et le choix des **m√©triques d‚Äô√©valuation** (MSE, RMSE, MAE, \(R^2\)) pour quantifier de fa√ßon honn√™te la qualit√© des pr√©dictions de progression.

L‚Äôenjeu final n‚Äôest pas seulement d‚Äôoptimiser une m√©trique math√©matique, mais de savoir si l‚Äôerreur r√©siduelle du mod√®le est compatible avec une **prise de d√©cision clinique s√ªre** (anticiper une aggravation, ajuster un traitement, surveiller un patient plus √©troitement).
